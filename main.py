import os, time, requests, threading
import urllib.parse
import html as html_parser
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# === æª”æ¡ˆæ—¥èªŒï¼š/tmp/worker.log ===
import logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s %(levelname)s: %(message)s',
    handlers=[
        logging.FileHandler('/tmp/worker.log'),
        logging.StreamHandler()
    ]
)
log = logging.getLogger(__name__)

DB_URL  = os.getenv('DB_URL')
BATCH   = int(os.getenv('BATCH', 20))

sess = requests.Session()
retries = Retry(total=3, backoff_factor=2, status_forcelist=[502, 503, 504])
sess.mount('https://', HTTPAdapter(max_retries=retries))

def update_status(row_id, status):
    """åªæ›´æ–°å¤±æ•ˆçš„å•†å“ç‹€æ…‹"""
    try:
        if status == 'å¤±æ•ˆ':
            data = {'id': row_id, 'status': status}
            sess.post(DB_URL, data=data, timeout=30)
            log.info("âœ… Recorded removed product: id=%s", row_id)
    except Exception as e:
        log.error("update_status failed: %s", e)

def check_removed(html):
    """ç²¾ç¢ºçš„ä¸‹æ¶æª¢æ¸¬ - é‡å°è¦çš®ä¸‹æ¶é é¢"""
    # è¨˜éŒ„éƒ¨åˆ†HTMLç”¨æ–¼é™¤éŒ¯ï¼ˆå‰500å­—ç¬¦ï¼‰
    html_preview = html[:500] if len(html) > 500 else html
    log.info("ğŸ“„ HTML preview: %s", html_preview)
    
    # ç¢ºåˆ‡çš„ä¸‹æ¶æ¨™èªŒ - åŸºæ–¼å¯¦éš›ä¸‹æ¶é é¢åˆ†æ
    exact_removed_indicators = [
        'product-not-exist__text">æ­¤å•†å“ä¸å­˜åœ¨</div>',  # å®Œæ•´HTMLæ¨™ç±¤
        'product-not-exist__text',                      # CSSé¡å
        'æ­¤å•†å“ä¸å­˜åœ¨',                                  # æ–‡å­—å…§å®¹
        'å•†å“å·²ä¸‹æ¶',
        'å¾ˆæŠ±æ­‰ï¼Œæ‚¨è¨ªå•çš„é é¢ä¸å­˜åœ¨',
        'è©²å•†å“å·²ä¸å­˜åœ¨'
    ]
    
    for indicator in exact_removed_indicators:
        if indicator in html:
            log.info("ğŸ¯ ç¢ºåˆ‡æª¢æ¸¬åˆ°ä¸‹æ¶æ¨™èªŒ: %s", indicator)
            return True
    
    # æª¢æŸ¥æ­£å¸¸å•†å“é é¢çš„ç‰¹å¾µ
    active_product_indicators = [
        'shopee-product-info',
        'product-detail',
        'item-review',
        'product-briefing',
        'add-to-cart',
        'åŠ å…¥è³¼ç‰©è»Š',
        'å•†å“è¦æ ¼',
        'å•†å“è©•åƒ¹'
    ]
    
    for indicator in active_product_indicators:
        if indicator in html:
            log.info("ğŸª æª¢æ¸¬åˆ°æ­£å¸¸å•†å“é é¢ç‰¹å¾µ: %s", indicator)
            return False
    
    # è¬¹æ…ä½¿ç”¨æ¨¡ç³Šæ¨™èªŒ
    weak_removed_indicators = [
        '404',
        'out of stock',
        'sold out'
    ]
    
    weak_match_count = 0
    for indicator in weak_removed_indicators:
        if indicator.lower() in html.lower():
            weak_match_count += 1
            log.info("âš ï¸ æª¢æ¸¬åˆ°æ¨¡ç³Šä¸‹æ¶æ¨™èªŒ: %s", indicator)
    
    # åªæœ‰åœ¨æ²’æœ‰æª¢æ¸¬åˆ°æ­£å¸¸é é¢ç‰¹å¾µæ™‚ï¼Œæ‰è€ƒæ…®æ¨¡ç³Šæ¨™èªŒ
    if weak_match_count >= 2:
        log.info("ğŸ¯ å¤šå€‹æ¨¡ç³Šæ¨™èªŒç¢ºèªå•†å“ä¸‹æ¶")
        return True
    
    # é è¨­æƒ…æ³ï¼šæ²’æœ‰æ˜ç¢ºè­‰æ“šå°±èªç‚ºå•†å“æœ‰æ•ˆ
    log.info("ğŸ” æœªæª¢æ¸¬åˆ°æ˜ç¢ºä¸‹æ¶è­‰æ“šï¼Œå•†å“åˆ¤å®šç‚ºæœ‰æ•ˆ")
    return False

def job():
    log.info("worker started - DB_URL: %s", DB_URL)
    
    # å–®æ¬¡åŸ·è¡Œ
    for attempt in range(3):
        try:
            params = {'limit': BATCH}
            log.info("ğŸ” å˜—è©¦å¾ API ç²å–å•†å“ (attempt %s)", attempt+1)
            
            # ç¦ç”¨å£“ç¸®ï¼Œç¢ºä¿èƒ½æ­£ç¢ºè§£æ JSON
            api_headers = {
                'User-Agent': 'ShopeeChecker/1.0',
                'Accept': 'application/json',
                'Accept-Encoding': 'identity'  # ç¦ç”¨å£“ç¸®
            }
            
            res = sess.get(DB_URL, params=params, timeout=30, headers=api_headers)
            
            # æ·»åŠ è©³ç´°é™¤éŒ¯ä¿¡æ¯
            log.info("ğŸ” API å›æ‡‰ç‹€æ…‹ç¢¼: %s", res.status_code)
            log.info("ğŸ” API å›æ‡‰æ¨™é ­: %s", dict(res.headers))
            
            if res.status_code != 200:
                log.warning("HTTP %s from API (attempt %s)", res.status_code, attempt+1)
                time.sleep(5)
                continue
                
            try:
                rows = res.json()
                log.info("âœ… æˆåŠŸè§£æ JSONï¼Œæ‰¾åˆ° %s å€‹å•†å“", len(rows))
                break
            except Exception as e:
                log.error("âŒ JSON è§£æå¤±æ•— (attempt %s): %s", attempt+1, e)
                log.error("âŒ å›æ‡‰å…§å®¹é–‹å§‹: %s", res.text[:200])
                time.sleep(5)
                continue
                
        except Exception as e:
            log.warning("fetch attempt %s failed: %s", attempt+1, e)
            time.sleep(5)
    else:
        log.error("ğŸš« ç²å–å•†å“å¤±æ•— 3 æ¬¡ï¼Œè·³éæœ¬è¼ªæª¢æŸ¥")
        return

    if not rows:
        log.info("ğŸ“­ No products to check")
        return

    removed_count = 0
    active_count = 0
    
    for r in rows:
        url = r['real_url']
        log.info("ğŸ” Checking product: %s", url)
        
        try:
            # å…è²»æ–¹æ¡ˆï¼šç›´æ¥è¨ªå•è¦çš®
            shopee_headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'zh-TW,zh;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br'
            }
            
            response = sess.get(url, headers=shopee_headers, timeout=30)
            log.info("ğŸ” è¦çš®é é¢ç‹€æ…‹ç¢¼: %s", response.status_code)
            
            html = response.text
            
            # ä½¿ç”¨ç²¾ç¢ºçš„ä¸‹æ¶æª¢æ¸¬
            if check_removed(html):
                status = 'å¤±æ•ˆ'
                removed_count += 1
                log.warning("ğŸš« Product REMOVED: %s", url)
            else:
                status = 'æœ‰æ•ˆ'
                active_count += 1
                log.info("âœ… Product ACTIVE: %s", url)
            
            update_status(r['id'], status)
            
        except Exception as e:
            log.error("âŒ è¨ªå•å•†å“é é¢å¤±æ•—: %s", e)
            continue

    log.info("ğŸ“Š Check completed: %s active, %s removed", active_count, removed_count)
    log.info("âœ… Single batch completed - exiting")

if __name__ == '__main__':
    job()